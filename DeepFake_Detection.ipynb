{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7cb0936",
      "metadata": {
        "id": "e7cb0936"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "def log_to_csv(filename, data):\n",
        "    file_exists = os.path.isfile(filename)\n",
        "    with open(filename, mode='a') as csv_file:\n",
        "        with open(filename, 'r', newline='') as file:\n",
        "            csv_reader = csv.reader(file)\n",
        "            l=[row for row in csv_reader]\n",
        "            if len(l)>0 and data[0]==0:\n",
        "                data[0]=int(l[-1][0])+data[0]+1\n",
        "        writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        if not file_exists:\n",
        "            writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision'])\n",
        "        writer.writerow(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "# Correct the path or file name if necessary\n",
        "sys.path.append('/content/drive/MyDrive/deep fake detection/')\n",
        "from Copy_of_autoencoder_detection_modified.ipynb import Classifier, data_define, train"
      ],
      "metadata": {
        "id": "HcGy8gCWN4Bp"
      },
      "id": "HcGy8gCWN4Bp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c695924f",
      "metadata": {
        "id": "c695924f"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/deep fake detection/') # Adjust the path if necessary\n",
        "from Copy_of_autoencoder_detection_modified import Classifier, data_define, train # Assuming these functions are defined in this file\n",
        "\n",
        "# ... rest of your code ...\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision.transforms import Compose\n",
        "import csv\n",
        "import os\n",
        "from train_mod import Classifier, data_define, train\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "inp=int(input('Train/Inference')) #input must 0/1\n",
        "if inp==0:\n",
        "    ds, trainloader=data_define('/content/')\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = Classifier().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    if os.path.exists('rf_face_det_weights.pth') and os.path.exists('rf_face_det_opt.pth'):\n",
        "        model.load_state_dict(torch.load('rf_face_det_weights.pth'))\n",
        "        optimizer.load_state_dict(torch.load('rf_face_det_opt.pth'))\n",
        "    n_epochs = 30 #changeable parameter\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc, train_fake_count, train_real_count, prec, cm = train(model, trainloader, criterion, optimizer)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'Training: Fake Images: {train_fake_count}, Real Images: {train_real_count}')\n",
        "        print('Confusion Matrix')\n",
        "        print(cm)\n",
        "        log_to_csv('train.csv', [epoch, train_loss, train_acc, prec])\n",
        "        torch.save(model.state_dict(),'rf_face_det_weights.pth')\n",
        "        torch.save(optimizer.state_dict(),'rf_face_det_opt.pth')\n",
        "elif inp==1:\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = Classifier().to(device)\n",
        "    model.load_state_dict(torch.load('rf_face_det_weights.pth'))\n",
        "    model.to(device)\n",
        "    st=int(input('Image/Video'))\n",
        "    if st==0:\n",
        "        from facenet_pytorch import MTCNN, InceptionResnetV1\n",
        "        from PIL import Image\n",
        "        import matplotlib.pyplot as plt\n",
        "        mtcnn = MTCNN()\n",
        "        model = Classifier().to(device)\n",
        "        image_path = '/home/developer/Downloads/example3'\n",
        "        image = Image.open(image_path)\n",
        "        boxes, probs = mtcnn.detect(image)\n",
        "        def crop_faces(image, boxes):\n",
        "            faces = []\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = box.astype(int)\n",
        "                faces.append(image.crop((x1, y1, x2, y2)))\n",
        "            return faces\n",
        "        cropped_faces = crop_faces(image, boxes)\n",
        "        num_faces = len(cropped_faces)\n",
        "        if num_faces > 0:\n",
        "            plt.imshow(cropped_faces[0])\n",
        "            plt.axis(False)\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No faces detected.\")\n",
        "\n",
        "\n",
        "        y=data_define(tensor=cropped_faces[0].convert('RGB')).cuda()\n",
        "        outputs=model(y.unsqueeze(0))\n",
        "        pred=torch.argmax(outputs,axis=1)\n",
        "        if pred==0:\n",
        "            print('real')\n",
        "        else:\n",
        "            print('fake')\n",
        "    elif st==1:\n",
        "        import cv2\n",
        "        import torch\n",
        "        from facenet_pytorch import MTCNN\n",
        "        from torchvision import transforms\n",
        "        from PIL import Image\n",
        "        import os\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        mtcnn = MTCNN(keep_all=True, device=device)\n",
        "\n",
        "        def load_model(a):\n",
        "            model = a\n",
        "            model.load_state_dict(torch.load('rf_face_det_weights.pth'))\n",
        "            model.to(device)\n",
        "            model.eval()\n",
        "            return model\n",
        "        def crop_faces(image, boxes):\n",
        "            faces = []\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = box.astype(int)\n",
        "                faces.append(image.crop((x1, y1, x2, y2)))\n",
        "            return faces\n",
        "        video_path = '/home/developer/Celeb-real/id0_0005.mp4'\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        if not cap.isOpened():\n",
        "            print(f\"Error opening video file {video_path}\")\n",
        "            exit()\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                boxes, probs = mtcnn.detect(rgb_frame)\n",
        "                if boxes is not None:\n",
        "                    for box in boxes:\n",
        "                        startX, startY, endX, endY = box.astype(int)\n",
        "                        face_region = frame[startY:endY, startX:endX]\n",
        "                        pil_image = Image.fromarray(cv2.cvtColor(face_region, cv2.COLOR_BGR2RGB))\n",
        "                        input_tensor = data_define(tensor=pil_image.convert('RGB')).cuda()\n",
        "                        outputs = model(input_tensor.unsqueeze(0))\n",
        "                        prediction = torch.argmax(outputs, dim=1).item()\n",
        "                        if prediction == 0:\n",
        "                            label = \"Real\"\n",
        "                            color = (0, 255, 0)\n",
        "                        else:\n",
        "                            label = \"Fake\"\n",
        "                            color = (0, 0, 255)\n",
        "                        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
        "                        cv2.putText(frame, label, (startX, startY - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)\n",
        "                cv2.imshow('Frame', frame)\n",
        "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "                    break\n",
        "            else:\n",
        "                break\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f4ac247",
      "metadata": {
        "id": "2f4ac247"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}