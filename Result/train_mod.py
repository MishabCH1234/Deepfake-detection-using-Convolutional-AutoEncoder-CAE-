# -*- coding: utf-8 -*-
"""Untitled53.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1772RWBvS8B1cbzYfWazNymHmeDqsNr4j
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.transforms import Compose, ToTensor
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
import os
import tqdm
from PIL import Image
import shutil
import csv
import zipfile
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def precision(y_pred, y_true):
    """
    Calculates precision for binary classification.

    Args:
    - y_pred (Tensor): Predicted labels (0 or 1).
    - y_true (Tensor): True labels (0 or 1).

    Returns:
    - precision (float): Precision score.
    """
    true_positives = torch.logical_and(y_pred == 1, y_true == 1).sum().item()
    predicted_positives = (y_pred == 1).sum().item()
    precision = true_positives / (predicted_positives + 1e-20)  # Adding epsilon to avoid division by zero
    return precision

def log_to_csv(filename, data):
    file_exists = os.path.isfile(filename)
    with open(filename, mode='a') as csv_file:
        writer = csv.writer(csv_file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
        if not file_exists:
            writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision'])
        writer.writerow(data)

class CustomDataset(Dataset):
    def __init__(self, data_folder, transform=None):
        self.data_folder = data_folder
        self.transform = transform

        # Get a list of all image files in the folder

        dirs=[os.path.join(data_folder,f) for f in os.listdir(data_folder)]
        #at=[os.path.join(data_folder,f) for f in os.listdir(data_folder) if f.endswith(('.jpg', '.jpeg', '.png', '.gif'))]
        self.image_files=[]
        ant=[dirs[0], dirs[1]]
        lab=torch.tensor([0, 1])
        for j,i in enumerate(dirs):
            self.image_files.extend([(os.path.join(ant[j],f),lab[j]) for f in os.listdir(i)])

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx][0]
        image = Image.open(img_name).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image[0].reshape(1,256,256), self.image_files[idx][1]

def data_define(data_folder=False, tensor=False):

    transform = Compose([
        ResizeToSquare(256),
        ToTensor()
    ])
    if data_folder:
        with zipfile.ZipFile(data_folder + 'test-20240703T060901Z-001.zip', 'r') as zip_ref:
            zip_ref.extractall()
        real=[os.path.join('/home/developer/celeb-real/celeb-real', i) for i in os.listdir('/home/developer/celeb-real/celeb-real')]
        fake=[os.path.join('/home/developer/celeb-fake/celeb-fake', i) for i in os.listdir('/home/developer/celeb-fake/celeb-fake')]
        for j,dir in enumerate([real, fake]):
            for i in dir:
                if j==0:
                    shutil.copy(i,'/home/developer/test-20240703T060901Z-001/test/real')
                else:
                    shutil.copy(i,'/home/developer/test-20240703T060901Z-001/test/fake')
        data_folder = '/home/developer/test-20240703T060901Z-001/test'
        custom_dataset = CustomDataset(data_folder, transform=transform)
        dataloader = DataLoader(custom_dataset, batch_size=100, shuffle=True)
        return custom_dataset, dataloader

    elif tensor:
        image= tensor
        if transform:
            image = transform(image)
        return image[0].reshape(1,256,256)

class ResizeToSquare(object):
    def __init__(self, size):
        self.size = size

    def __call__(self, img):
        width, height = img.size
        aspect_ratio = width / height
        if aspect_ratio > 1:
            new_width = self.size
            new_height = int(self.size / aspect_ratio)
        else:
            new_height = self.size
            new_width = int(self.size * aspect_ratio)
        img = img.resize((new_width, new_height))
        canvas = Image.new('RGB', (self.size, self.size), (0, 0, 0))
        h_offset = (self.size - new_width) // 2
        v_offset = (self.size - new_height) // 2
        canvas.paste(img, (h_offset, v_offset))
        return canvas

class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()

        # Encoder
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 128, kernel_size=5, stride=2, padding=2),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv2d(256, 512, kernel_size=5, stride=2, padding=2),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv2d(512, 1024, kernel_size=5, stride=2, padding=2),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Flatten(),
            nn.Linear(1024 * 16 * 16, 1024),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Linear(1024, 2)  # Two output classes: real or fake
        )

        # Decoder
        self.decoder_fc = nn.Sequential(
            nn.Linear(2, 1024),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Linear(1024, 1024 * 16 * 16),
            nn.LeakyReLU(0.1, inplace=True)
        )

        self.decoder_conv = nn.Sequential(
            nn.Unflatten(1, (1024, 16, 16)),
            nn.ConvTranspose2d(1024, 512, kernel_size=5, stride=2, padding=2, output_padding=1),
            nn.LeakyReLU(0.1, inplace=True),
            nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1),
            nn.LeakyReLU(0.1, inplace=True),
            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),
            nn.LeakyReLU(0.1, inplace=True),
            nn.ConvTranspose2d(128, 3, kernel_size=5, stride=2, padding=2, output_padding=1),
            nn.Sigmoid()  # To get pixel values in the range [0, 1]
        )

    def forward(self, x):
        encoded = self.encoder(x)
        return encoded

    def decode(self, encoding):
        x = self.decoder_fc(encoding)
        x = self.decoder_conv(x)
        return x

def train(model, dataloader, criterion, optimizer):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    fake_count = 0
    real_count = 0
    datal=tqdm.tqdm(dataloader)
    for images, labels in datal:

        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

        # Counting real and fake images
        fake_count += (predicted == 1).sum().item()
        real_count += (predicted == 0).sum().item()

        datal.set_postfix(loss=running_loss)

    accuracy = 100. * correct / total
    outputs=torch.argmax(outputs, dim=1)
    prec=precision(outputs,labels)
    return running_loss / len(dataloader), accuracy, fake_count, real_count, prec